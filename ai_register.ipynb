{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ai-register",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/analimazn/artificial-intelligence/blob/master/ai_register.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEocZ3pRA7mQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2 \n",
        "import os\n",
        "import numpy as np "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o76mcXKA9Ug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Open the image files. \n",
        "img2_color = cv2.imread(\"GE01_2011_JPEG_R1C1.jpg\") # Reference image.\n",
        "img2 = cv2.cvtColor(img2_color, cv2.COLOR_BGR2GRAY)\n",
        "height, width = img2.shape "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaDy_8IxGEGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATADIR = \"./data\"\n",
        "path = os.path.join(DATADIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPxncbJZCz1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for img in os.listdir(path):\n",
        "    try:\n",
        "        img1_color = cv2.imread(os.path.join(path, img)) # Image to be aligned.\n",
        "        img1 = cv2.cvtColor(img1_color, cv2.COLOR_BGR2GRAY) \n",
        "        \n",
        "        # Create ORB detector with 5000 features. \n",
        "        orb_detector = cv2.ORB_create(5000)\n",
        "        \n",
        "        # Find keypoints and descriptors. \n",
        "        # The first arg is the image, second arg is the mask \n",
        "        # (which is not reqiured in this case). \n",
        "        kp1, d1 = orb_detector.detectAndCompute(img1, None) \n",
        "        kp2, d2 = orb_detector.detectAndCompute(img2, None)\n",
        "        \n",
        "        # Match features between the two images. \n",
        "        # We create a Brute Force matcher with \n",
        "        # Hamming distance as measurement mode. \n",
        "        matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
        "        \n",
        "        # Match the two sets of descriptors. \n",
        "        matches = matcher.match(d1, d2)\n",
        "        \n",
        "        # Sort matches on the basis of their Hamming distance. \n",
        "        matches.sort(key = lambda x: x.distance)\n",
        "        \n",
        "        # Take the top 90 % matches forward. \n",
        "        matches = matches[:int(len(matches)*90)] \n",
        "        no_of_matches = len(matches)\n",
        "        \n",
        "        # Define empty matrices of shape no_of_matches * 2. \n",
        "        p1 = np.zeros((no_of_matches, 2)) \n",
        "        p2 = np.zeros((no_of_matches, 2))\n",
        "        \n",
        "        for i in range(len(matches)): \n",
        "            p1[i, :] = kp1[matches[i].queryIdx].pt \n",
        "            p2[i, :] = kp2[matches[i].trainIdx].pt \n",
        "        \n",
        "        # Find the homography matrix. \n",
        "        homography, mask = cv2.findHomography(p1, p2, cv2.RANSAC)\n",
        "        \n",
        "        # Use this matrix to transform the \n",
        "        # colored image wrt the reference image. \n",
        "        transformed_img = cv2.warpPerspective(img1_color, \n",
        "                            homography, (width, height))\n",
        "        \n",
        "        # Save the output. \n",
        "        cv2.imwrite('./output/newimg' + img + '.jpg', transformed_img) \n",
        "        \n",
        "    except Exception as e:\n",
        "        pass\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}